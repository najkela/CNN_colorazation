{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models # type: ignore\n",
    "\n",
    "def LoadImagesFromFolder(folder, size = (256, 256), batch_size = 32):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        folder,\n",
    "        validation_split = 0.2,\n",
    "        subset = \"training\",\n",
    "        seed = 123,\n",
    "        image_size = size, \n",
    "        batch_size = batch_size,\n",
    "        label_mode = None,\n",
    ")\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        folder,\n",
    "        validation_split = 0.2,\n",
    "        subset = \"validation\",\n",
    "        seed = 123,\n",
    "        image_size = size,\n",
    "        batch_size = batch_size,\n",
    "        label_mode = None\n",
    ")\n",
    "\n",
    "    return dataset, val_ds\n",
    "\n",
    "def EditImage(image):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    hsv_image = tf.image.rgb_to_hsv(image)\n",
    "\n",
    "    h = hsv_image[:, :, :, 0]\n",
    "    s = hsv_image[:, :, :, 1]\n",
    "    v = hsv_image[:, :, :, 2]\n",
    "\n",
    "    hs = tf.stack([h, s], axis=-1)\n",
    "    v = tf.expand_dims(v, axis=-1)\n",
    "\n",
    "    return hs, v\n",
    "\n",
    "def PreprocessImages(dataset):\n",
    "    hs_images = dataset.map(lambda image: EditImage(image)[0])\n",
    "    v_images = dataset.map(lambda image: EditImage(image)[1])\n",
    "\n",
    "    return tf.data.Dataset.zip((v_images, hs_images))\n",
    "\n",
    "def MakeModel(input_size=(128, 128, 1)):\n",
    "    size = input_size[0]\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(size // 2, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(size // 2, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(size, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(size, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(2 * size, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(2 * size, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = layers.Conv2DTranspose(size, 2, strides=(2, 2), padding='same')(conv3)\n",
    "    merge4 = layers.concatenate([conv2, up4], axis=3)\n",
    "    conv4 = layers.Conv2D(size, 3, activation='relu', padding='same')(merge4)\n",
    "    conv4 = layers.Conv2D(size, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = layers.Conv2DTranspose(size // 2, 2, strides=(2, 2), padding='same')(conv4)\n",
    "    merge5 = layers.concatenate([conv1, up5], axis=3)\n",
    "    conv5 = layers.Conv2D(size // 2, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = layers.Conv2D(size // 2, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(2, 1, activation='sigmoid')(conv5)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pravljenje modela\n",
    "model = MakeModel(input_size = (256, 256, 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "# Učitavanje fajlova\n",
    "folder_path = './mid_smaller_dataset'\n",
    "dataset, val = LoadImagesFromFolder(folder_path, size = (256, 256), batch_size = 16)\n",
    "dataset = PreprocessImages(dataset)\n",
    "val = PreprocessImages(val)\n",
    "\n",
    "# Treniranje modela\n",
    "history = model.fit(dataset, epochs = 100, validation_data = val)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.savefig(\"Model loss\")\n",
    "\n",
    "# Čuvanje istreniranog modela\n",
    "model.save('AI.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
